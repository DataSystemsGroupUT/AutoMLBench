
# Results
* [Tables and Results Summaries](#tables-and-results-summaries)



## Tables and Results Summaries

### Comparison table of functionality of the AutoML frameworks

<figure>
<img src="https://raw.githubusercontent.com/DataSystemsGroupUT/AutoMLBench/d79bc51f0e4dafc00528b34e13890d1d89c95cc4/docs/data/tables/T1.png" alt="Comparison table of functionality of the AutoML frameworks considered in this study as of 24/12/2021" style="width:750px;"/>

</figure>

### Wilcoxon pairwise test p-values for AutoML frameworks over different time budgets.

<figure>
<img src="https://raw.githubusercontent.com/DataSystemsGroupUT/AutoMLBench/d79bc51f0e4dafc00528b34e13890d1d89c95cc4/docs/data/tables/T2.png" alt="Wilcoxon pairwise test p-values for AutoML frameworks over different time budgets." style="width:750px;"/>

</figure>

### Mean_Succ, Mean and standard deviation of the predictive performance of AutoML frameworks

<figure>
<img src="https://raw.githubusercontent.com/DataSystemsGroupUT/AutoMLBench/d79bc51f0e4dafc00528b34e13890d1d89c95cc4/docs/data/tables/T3.png" alt="Mean_Succ, Mean and standard deviation of the predictive performance of AutoML frameworks." style="width:750px;"/>

</figure>

### Summary of the impact of increasing the time budget.

<figure>
<img src="https://raw.githubusercontent.com/DataSystemsGroupUT/AutoMLBench/d79bc51f0e4dafc00528b34e13890d1d89c95cc4/docs/data/tables/T4.png" alt="Summary of the impact of increasing the time budget." style="width:750px;"/>

</figure>

### Wilcoxon test p-values for all the AutoML frameworks 
<figure>
<img src="https://raw.githubusercontent.com/DataSystemsGroupUT/AutoMLBench/d79bc51f0e4dafc00528b34e13890d1d89c95cc4/docs/data/tables/T5.png" alt="Wilcoxon test p-values for all the AutoML frameworks." style="width:750px;"/>

</figure>

### The performance of AutoSklearn-v and AutoSklearn-m and the gain in performance

<figure>
<img src="https://raw.githubusercontent.com/DataSystemsGroupUT/AutoMLBench/d79bc51f0e4dafc00528b34e13890d1d89c95cc4/docs/data/tables/T6.png" alt="The performance of AutoSklearn-v and AutoSklearn-m and the gain in performance." style="width:750px;"/>

</figure>

### Performance comparison between vanilla/base version vs ensembling version of AutoSKlearn and SmartML

<figure>
<img src="https://raw.githubusercontent.com/DataSystemsGroupUT/AutoMLBench/d79bc51f0e4dafc00528b34e13890d1d89c95cc4/docs/data/tables/T7.png" alt="Performance comparison between vanilla/base version vs ensembling version of AutoSKlearn and SmartML" style="width:750px;"/>

</figure>

## General performance trends of the benchmark AutoML frameworks

<figure>
<img src="https://raw.githubusercontent.com/DataSystemsGroupUT/AutoMLBench/67991ef92774380b30d7ccdd8ad68eec2c6a44a0/docs/data/pdf2png/No_of_times_the_tool_has_succeeded_to_return_a_model-1.png" alt="Number of successful runs" style="width:750px;"/>
<figcaption> Number of successful runs</figcaption>
</figure>

<figure>
<img src="https://raw.githubusercontent.com/DataSystemsGroupUT/AutoMLBench/67991ef92774380b30d7ccdd8ad68eec2c6a44a0/docs/data/pdf2png/box_plot_240%20Min-1.png" alt="Performance of the final pipeline per AutoML framework for 240 minutes" style="width:750px;"/>
<figcaption>Performance of the final pipeline per AutoML framework for 240 minutes</figcaption>
</figure>


<figure>
<img src="https://raw.githubusercontent.com/DataSystemsGroupUT/AutoMLBench/37a3b533f6cdc7942555009b4b3ae6475f0b8c80/docs/data/bench_figs/Fig3.png" alt="Heatmaps" style="width:750px;"/>
<figcaption>Heatmaps show the number of datasets a given AutoML framework outperforms another in terms
of predictive performance over different time budgets. Two frameworks are considered to have the same
performance on a task if they achieve predictive performance within 1% of each other.</figcaption>
</figure>

<figure>
<figure>
<img src="https://raw.githubusercontent.com/DataSystemsGroupUT/AutoMLBench/37a3b533f6cdc7942555009b4b3ae6475f0b8c80/docs/data/bench_figs/Fig4a.png" alt="Performance" style="width:750px;"/>
<figcaption>Performance of the final pipeline on multi-class classification tasks</figcaption>
</figure>

<figure>
<img src="https://raw.githubusercontent.com/DataSystemsGroupUT/AutoMLBench/37a3b533f6cdc7942555009b4b3ae6475f0b8c80/docs/data/bench_figs/Fig4b.png" alt="Performance" style="width:750px;"/>
<figcaption>Performance of the final pipeline on datasets with large number of features and small
number of instances.</figcaption>
</figure>

<figcaption>Performance of the different AutoML frameworks based on the various characteristics of datasets
and tasks over 240 minutes.</figcaption>
</figure>

<figure>
<img src="https://raw.githubusercontent.com/DataSystemsGroupUT/AutoMLBench/37a3b533f6cdc7942555009b4b3ae6475f0b8c80/docs/data/bench_figs/Fig5.png" alt="Evaluation" style="width:750px;"/>
<figcaption>Evaluation of AutoML frameworks on robustness</figcaption>
</figure>

<figure>
<img src="https://raw.githubusercontent.com/DataSystemsGroupUT/AutoMLBench/9b93e5d39a5364f31a0de2e88ebc2e6c48036c21/docs/data/bench_figs/Fig6.png" alt="Performance" style="width:750px;"/>
<figcaption>The frequency of using different machine learning models by the different AutoML frameworks.</figcaption>
</figure>

<figure>
<img src="https://raw.githubusercontent.com/DataSystemsGroupUT/AutoMLBench/37a3b533f6cdc7942555009b4b3ae6475f0b8c80/docs/data/bench_figs/Fig7.png" alt="Performance" style="width:750px;"/>
<figcaption>The impact of using a static portfolio on each AutoML framework. Green markers represent better
performance with F C search space, blue markers represent comparable performance with a difference
less than 1%, red markers represent better performance with 3C search space, yellow markers on the left
represent failed runs with F C but successful with 3C, yellow markers on the right represent failed runs
with 3C but successful with F C, and yellow markers in the middle represent failed runs with both F C
and 3C</figcaption>
</figure>